В целом тот же sql но с python кодом
- 3 способа написания - python, SPark, SQL
Общие моменты
1. Что выводит Спарк? Таблицу , ее можно сохранить в HDFS(Hadoop), S3, CSV, Parquest
2. Pandas VS Spark. Pandas - работает локально, а Spark- распределенно.
3. YARN -yet another resource negotiator , или же Менеджер Ресурсов. Он выдает ресурсы каждому executor
4. Спарк запускает задачи через executor в виде Java процессов
5. Executor забирает память и ядра с каждого сервера для запуска.
6. Driver- может:
- создавать executor
- убивать executor
- перезапускать executor
7. Можем задать количество executor: spark.executor.instances -> 6
8. Spark нуждается лишь в RAM так как вся работа происходит на ней.
9. Как Spark читает данные с диска? Условно имеет 1 Гб таблицу, и 10 экзекьюторов. Можно и больше но будет проблема при соединении в момент сохранения данных из Spark на диск. Так как они сохранятся в том же количестве в котором были разбиты.
10. 1 partition = 1 core = 1 task
11.  Операция shuffle (orderBy, groupBy, join)- по факту перемешивание данных между executors. Тяжелый процесс и в идеале следует стремится уменьшать кол-во таких операций.
12. Каждый сервер по умолчанию жрет ресурс для ресурсного менеджера yarn/hadoop и его ОС (1 ядра и 1 гб RAM). 
13. Каждый executor жрет ресурсы сервера тоже (N cores, N Gb Ram). 
14. На драйвер тоже выделяется обычно 1 ядро и 1 гб Рам для всего кластера (а не на каждый сервер как yarn/hadoop)
15. Если запускать Спарк локально, то yarn не забирает ресурсы, мы по сути отдаем все ресурсы Спарку и даем им пользоваться. С драйвера мы запускаемся.
Тут сразу нюанс (аналогия варки борща):
- Если выделить 1 ядро с сервака на экзекьютор, то получим 150/1 - 150 executors. Это хороший параллелизм, но много shuffle и операций I/O.
- ПРи этом если 5 ядер из 16, то уже будет 150/5=30 executors. В целом рекомендуют от 2х, максимум до 5 cores.
- Ну и больше это уже не эффективно, условно 16 ядер это 150/16=9 executors. Тут мало shuffle и малый праллелизм


## Сколько нужно ресурсов ?

![[Pasted image 20241125222522.png]]


### Память в executor'е ?

![[спарк память в ексекьжюторе.png]]Работа со Spark
 1.  Спарк ленивый и просто назначить в переменную csv файл не получится. Нужно написать .show() или .count() 