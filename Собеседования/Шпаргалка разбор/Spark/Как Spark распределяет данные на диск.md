### **Рекомендации по записи данных на диск в Spark**

#### **1. Как Spark сохраняет данные на диск**

1. Для каждой партиции создаётся отдельный файл.
    - Если у RDD 100 партиций, Spark создаст 100 файлов.
2. Данные в файлах сохраняются в порядке партиций:
    - Файл `part-00000` содержит данные первой партиции.
    - Файл `part-00001` содержит данные второй партиции и так далее.

---

#### **2. Почему большое количество партиций замедляет запись**

1. **Множество мелких файлов:**
    - Если каждая партиция содержит мало данных, создаётся множество маленьких файлов.
    - Это вызывает:
        - Большую нагрузку на файловую систему.
        - Замедление загрузки при чтении данных в будущем.
2. **Накладные расходы на файловую систему:**
    - Большое количество файлов увеличивает время записи.

---

#### **3. Уменьшение числа партиций перед записью**

- Если данных немного, уменьшение числа партиций помогает сократить количество файлов.
- Используй метод `coalesce`:
    
    
    `rdd = sc.parallelize(range(1, 10001), numSlices=100) rdd.coalesce(10).saveAsTextFile("output")`
    
    - Из 100 партиций создаётся только 10 файлов.

#### **Когда уменьшать партиции:**

- Данные небольшие, и нужно создать меньше файлов.
- Данные уже отсортированы или агрегированы.

#### **Когда НЕ уменьшать партиции:**

- Данные большие, и одна партиция может не поместиться в память.

---

#### **4. Увеличение числа партиций перед записью**

Иногда перед записью нужно увеличить число партиций, чтобы перераспределить данные:

- Используй `repartition`:
    
    `balanced_rdd = rdd.repartition(10) balanced_rdd.saveAsTextFile("output")`
    
- **Когда это уместно:**
    - Если данные распределены неравномерно.
    - Одна или несколько партиций перегружены.

---

#### **5. Итоговые рекомендации**

1. **Оптимальное количество партиций:**
    - Для больших данных одна партиция ≈ 128 МБ (по умолчанию, размер блока HDFS).
    - Уменьшай число партиций перед записью, если нужно сократить количество файлов.
2. **Используй `coalesce`, если нужно уменьшить число партиций без shuffle.**
3. **Используй `repartition`, если данные распределены неравномерн**