### **Партиции в Spark**

#### **1. Что такое партиции и как они работают?**

1. **Определение:** Партиция — это минимальная единица данных, обрабатываемая Spark.  
    Каждый executor обрабатывает данные одной или нескольких партиций.
    
2. **Как данные обрабатываются:**
    
    - **Внутри каждой партиции:** Spark выполняет локальную обработку (например, `map`, `filter`) для сокращения объёма данных.
    - **Между партициями:** При необходимости данные объединяются через shuffle (например, в операциях `join` или `reduceByKey`).

---

#### **2. Механизм распределения данных по партициям**

1. **Метод распределения:** Spark использует хэш-функцию для операций с ключами:
    
    `partition = hash(key) % numPartitions`
    
    Пример:
    
    `rdd = sc.parallelize([("a", 1), ("b", 2)], numSlices=2) partitioned_rdd = rdd.partitionBy(2) print(partitioned_rdd.glom().collect()) # [(("b", 2)), (("a", 1))]`
    
2. **Как проверить распределение:**
    
    - Используй `glom()` для анализа данных в партициях:
        
        `print(rdd.glom().collect())`
        

---

#### **3. Восстановление данных из утерянной партиции**

1. **Как Spark восстанавливает данные:**
    
    - Spark не сохраняет копии данных. Вместо этого он использует **DAG** для повторного выполнения операций.
    - Если исходные данные доступны, потерянные партиции пересчитываются автоматически.
2. **Ограничения:**
    
    - Если данные удалены с исходного источника, восстановление невозможно.
    - Действия, такие как `collect`, завершают выполнение DAG, и повторное вычисление невозможно.

---

#### **4. Локальная и глобальная агрегация**

1. **Как работает `reduceByKey`:**
    
    - Сначала выполняется локальная агрегация внутри каждой партиции.
    - Затем глобальная агрегация между партициями. Пример:

    
    `rdd = sc.parallelize([("a", 1), ("b", 2), ("a", 3)], numSlices=2) result = rdd.reduceByKey(lambda x, y: x + y) print(result.collect())`
    
2. **Преимущество:** Локальная агрегация уменьшает объём данных, передаваемых через shuffle.
    

---

#### **5. Как выбрать оптимальное количество партиций**

1. **Рекомендации:**
    
    - **Одна партиция ≈ 128 МБ данных.**
    - Число партиций должно быть кратно числу доступных ядер:
        
        `numPartitions = available_cores * 2–3`
        
2. **Формула:**
    
    `numPartitions = max(total_data_size_MB / 128, available_cores * 2)`
    
3. **Когда увеличивать партиции:**
    
    - Если данные распределены неравномерно.
    - Если одна или несколько партиций слишком велики для памяти executor'а.
4. **Когда уменьшать партиции:**
    
    - Если партиций слишком много, что приводит к scheduler overhead.
    - Если данные уже агрегированы или отсортированы.

---

### **Итог**

- Партиции — это ключевой механизм распределённой обработки в Spark.
- Для операций с ключами используется хэш-функция, чтобы равномерно распределить данные.
- Локальная и глобальная агрегация помогают уменьшить объём shuffle.
- Всегда настраивай количество партиций в зависимости от объёма данных и числа ядер.
