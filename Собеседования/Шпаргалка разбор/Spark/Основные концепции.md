## Основные концепции

1. **Что выводит Spark?**
    
    - Spark выводит таблицы, которые можно сохранить в различных форматах, таких как HDFS (Hadoop), S3, CSV, Parquet.
2. **Pandas vs Spark:**
    
    - **Pandas:** Работает локально.
    - **Spark:** Работает распределенно.
3. **YARN (Yet Another Resource Negotiator):**
    
    - YARN — это менеджер ресурсов, который выдает ресурсы каждому executor.
4. **Запуск задач через executor:**
    
    - Spark запускает задачи через executor в виде Java процессов.
5. **Использование ресурсов executor:**
    
    - Executor забирает память и ядра с каждого сервера для запуска.
6. **Функции driver:**
    
    - Driver может:
        - Создавать executor.
        - Убивать executor.
        - Перезапускать executor.
7. **Количество executor:**
    
    - Можно задать количество executor с помощью параметра `spark.executor.instances`.
8. **Использование RAM:**
    
    - Spark нуждается в RAM, так как вся работа происходит на ней.
9. **Чтение данных с диска:**
    
    - Spark читает данные с диска и распределяет их по executor. Например, если у вас есть 1 ГБ таблица и 10 executor, данные будут распределены между ними.
10. **Партиции, ядра и задачи:**
    
    - 1 partition = 1 core = 1 task.
11. **Операция shuffle:**
    
    - Операции shuffle (например, `orderBy`, `groupBy`, `join`) перемешивают данные между executor. Это тяжелый процесс, и в идеале следует стремиться уменьшать количество таких операций.
12. **Ресурсы для ресурсного менеджера:**
    
    - Каждый сервер по умолчанию выделяет ресурсы для ресурсного менеджера YARN/Hadoop и его ОС (1 ядро и 1 ГБ RAM).
13. **Ресурсы для executor:**
    
    - Каждый executor также использует ресурсы сервера (N ядер, N ГБ RAM).
14. **Ресурсы для driver:**
    
    - На driver обычно выделяется 1 ядро и 1 ГБ RAM для всего кластера (а не на каждый сервер как для YARN/Hadoop).
15. **Локальный запуск Spark:**
    
    - При локальном запуске Spark, YARN не забирает ресурсы, и все ресурсы отдаются Spark. Запуск происходит с driver.
Тут сразу нюанс (аналогия варки борща):
## Распределение ядер на executors

- **1 ядро на executor:**
    
    - 150/1 = 150 executors. Хороший параллелизм, но много shuffle и операций I/O.
- **5 ядер из 16:**
    
    - 150/5 = 30 executors. Рекомендуется от 2 до 5 ядер.
- **16 ядер:**
    
    - 150/16 = 9 executors. Мало shuffle и малый параллелизм.
1. **Ленивые вычисления:**
    - Spark ленивый и просто назначить в переменную CSV файл не получится. Нужно написать `.show()` или `.count()` для запуска вычислений.
#### **Как выбрать оптимальное количество партиций?**

- **Общее правило:**  
    Количество партиций ≈ 2–3 партиции на каждое ядро в кластере. Например, для 4 ядер оптимально использовать 8–12 партиций.
### Память в executor'е ?

![[спарк память в ексекьжюторе.png]]


## Дополнительные важные моменты

1. **SparkSession:**
    
    - `SparkSession` — это точка входа для работы с DataFrame и SQL. Он предоставляет единый интерфейс для работы с данными.
2. **DataFrame и Dataset:**
    
    - **DataFrame:** Высокоуровневая абстракция данных, которая предоставляет API для работы с данными в виде таблиц.
    - **Dataset:** Типизированная версия DataFrame, которая предоставляет дополнительные возможности для работы с данными.
3. **RDD (Resilient Distributed Dataset):**
    
    - Основная абстракция данных в Spark, представляющая собой распределенный набор данных. RDD поддерживает трансформации и действия.
4. **Spark SQL:**
    
    - Модуль для работы с данными с использованием SQL-запросов. Позволяет выполнять сложные запросы и агрегации.
5. **Spark Streaming:**
    
    - Модуль для обработки данных в реальном времени. Позволяет обрабатывать потоковые данные из различных источников, таких как Kafka, Flume и другие.
6. **MLlib:**
    
    - Библиотека для машинного обучения, которая предоставляет алгоритмы для классификации, регрессии, кластеризации и других задач.
7. **GraphX:**
    
    - Библиотека для обработки графов. Позволяет выполнять сложные операции с графами, такие как анализ социальных сетей и рекомендательные системы.
8. **Оптимизация производительности:**
    
    - **Кэширование:** Используйте `.cache()` или `.persist()` для сохранения промежуточных результатов в памяти или на диске.
    - **Партиции:** Правильное количество партиций может значительно улучшить производительность. Используйте `.repartition()` или `.coalesce()` для изменения количества партиций.
    - **Шардинг:** Распределение данных по ключам может уменьшить количество операций shuffle.
9. **Мониторинг и отладка:**
    
    - **Spark UI:** Веб-интерфейс для мониторинга выполнения задач. Позволяет отслеживать статус задач, использование ресурсов и другие метрики.
    - **Логи:** Используйте логи для отладки и анализа ошибок. Логи можно настроить для вывода в консоль или в файл.
10. **Безопасность:**
    
    - **Аутентификация и авторизация:** Настройте аутентификацию и авторизацию для защиты данных и ресурсов.
    - **Шифрование:** Используйте шифрование для защиты данных при передаче и хранении.



# Распределение памяти на Executor в Spark

## Общие сведения

В Spark память на executor распределяется между различными компонентами для обеспечения эффективной работы и управления ресурсами. Основные компоненты включают:

1. **Память для вычислений (Execution Memory):**
    
    - Используется для выполнения задач и хранения промежуточных данных во время вычислений.
2. **Память для хранения (Storage Memory):**
    
    - Используется для кэширования данных, таких как RDD, DataFrame и Dataset, а также для широковещательных переменных.
3. **Резервная память (Other Memory):**
    
    - Включает память, выделенную для внутренних структур данных Spark, буферов и других вспомогательных компонентов.

## Распределение памяти

### Параметры конфигурации

- **spark.memory.fraction:**
    
    - Определяет долю общей памяти executor, которая будет использоваться для вычислений и хранения. По умолчанию это значение составляет 0.6 (60%).
- **spark.memory.storageFraction:**
    
    - Определяет долю памяти, выделенной для хранения, из общей памяти, определенной `spark.memory.fraction`. По умолчанию это значение составляет 0.5 (50%).

### Пример распределения памяти

Предположим, что у нас есть executor с 10 ГБ памяти:

1. **Общая память для вычислений и хранения:**
    
    - `spark.memory.fraction` = 0.6
    - 10 ГБ * 0.6 = 6 ГБ
2. **Память для хранения:**
    
    - `spark.memory.storageFraction` = 0.5
    - 6 ГБ * 0.5 = 3 ГБ
3. **Память для вычислений:**
    
    - Остальная память из 6 ГБ: 6 ГБ - 3 ГБ = 3 ГБ
4. **Резервная память:**
    
    - Остальная память из 10 ГБ: 10 ГБ - 6 ГБ = 4 ГБ



