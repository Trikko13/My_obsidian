**2. Распределение ресурсов и управление памятью**

#### **2.1 Как Spark использует ресурсы?**

1. **Executor:**
    
    - Каждый executor — это Java-процесс, который:
        - Выполняет задачи (tasks) на выделенных ядрах.
        - Использует выделенную память для вычислений и хранения данных.
    - Ресурсы executor'ов задаются с помощью параметров:
        
        `spark.executor.memory  # Память для executor (например, 4g) spark.executor.cores   # Количество ядер на executor (например, 2)`
        
2. **Driver:**
    
    - Driver отвечает за:
        - Планирование задач и их распределение между executor'ами.
        - Координацию выполнения.
    - Ресурсы driver задаются так:
        
        `spark.driver.memory  # Память для driver (например, 1g) spark.driver.cores   # Ядра для driver (например, 1)`
        
3. **Ресурсный менеджер (например, YARN):**
    
    - Управляет распределением ресурсов в кластере.
    - Выделяет ядра и память для каждого executor и driver.

---

#### **2.2 Распределение памяти в executor**

Spark делит память executor'а на три основные части:

1. **Execution Memory (для вычислений):**
    
    - Используется для выполнения операций (например, `join`, `groupByKey`).
    - Промежуточные данные хранятся в этой области.
2. **Storage Memory (для хранения):**
    
    - Используется для кэширования данных (например, RDD, DataFrame).
    - Если память для хранения не используется, она временно выделяется для вычислений.
3. **Reserved Memory (дополнительная):**
    
    - Включает системные нужды Spark (например, буферы).

#### **Конфигурация памяти:**

1. `spark.memory.fraction` (по умолчанию: 0.6):
    
    - Доля общей памяти executor'а, выделенная для вычислений и хранения.
2. `spark.memory.storageFraction` (по умолчанию: 0.5):
    
    - Доля памяти, выделенной для хранения из общей памяти `spark.memory.fraction`.

**Пример распределения:**

- Память executor: 10 ГБ.
- `spark.memory.fraction` = 0.6 → 60% от 10 ГБ = 6 ГБ.
- `spark.memory.storageFraction` = 0.5 → 50% от 6 ГБ = 3 ГБ для хранения, 3 ГБ для вычислений.
- Остальные 4 ГБ выделены для системных нужд.

---

#### **2.3 Партиции, задачи и ядра**

1. **1 партиция = 1 задача (task) = 1 ядро:**
    
    - Каждая партиция обрабатывается одним ядром.
    - Чем больше партиций, тем больше задач может выполняться параллельно.
2. **Рекомендации по числу партиций:**
    
    - Оптимальное число партиций: 2–3 партиции на каждое ядро.
    - Формула:
        
        `numPartitions = total_cores * 2–3`
        

#### **Пример:**

- Данных: 10 ГБ.
- Ядра: 16.
- Оптимальное число партиций:
    
    `numPartitions = 16 * 3 = 48`
    

---

#### **2.4 Как оптимизировать использование ресурсов?**

1. **Используй правильное количество executor:**
    
    - Задай количество executor в конфигурации:
        
        `spark.executor.instances = 10`
        
2. **Настрой память executor:**
    
    - Задай память, подходящую для твоих данных:
        
        `spark.executor.memory = "4g"`
        
3. **Избегай больших перекосов в данных:**
    
    - Увеличь число партиций, если одна партиция перегружена:
        
        `repartitioned_rdd = rdd.repartition(16)`
        
4. **Кэшируй часто используемые данные:**
    
    - Кэширование ускоряет повторное использование RDD:
        `cached_rdd = rdd.cache()`
        

---

### **Итоговые рекомендации**

- Следи за сбалансированным использованием памяти и ядер.
- Подбирай количество партиций так, чтобы максимально использовать доступные ядра.
- Используй кэширование и правильное распределение ресурсов, чтобы избежать узких мест.