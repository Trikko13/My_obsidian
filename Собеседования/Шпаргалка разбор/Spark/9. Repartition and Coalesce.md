#### **Часть 1: `Repartition` и `Coalesce` — основные концепции**

1. **Что делают `repartition` и `coalesce`:**
    
    - `Repartition`: увеличивает или уменьшает количество партиций с shuffle.
    - `Coalesce`: уменьшает количество партиций, избегая shuffle, если явно не указать `shuffle=True`.
2. **Ключевые различия:**
    

| Метод             | Описание                                                                             | Когда использовать                                                                                 |
| ----------------- | ------------------------------------------------------------------------------------ | -------------------------------------------------------------------------------------------------- |
| **`coalesce`**    | Уменьшает количество партиций, стараясь избежать shuffle.                            | Когда нужно сократить партиции после фильтрации или перед записью.                                 |
| **`repartition`** | Увеличивает/уменьшает партиции с равномерным распределением данных (shuffle всегда). | Когда нужно перераспределить данные для равномерной обработки или увеличить партиции перед `join`. |

---

#### **Часть 2: Best practices**

1. **Всегда проверяйте размер данных перед изменением партиций.**
    
    - Используй `glom()` для анализа распределения данных:
        
        `partition_lengths = rdd.glom().map(len).collect() print("Элементов в каждой партиции:", partition_lengths)`
        
2. **Используй `coalesce` для уменьшения партиций.**
    
    - **Без shuffle:**  
        Применяй `coalesce` для уменьшения числа партиций после фильтрации:
        
        `filtered_rdd = rdd.filter(lambda x: x > 10).coalesce(2)`
        
    - **С shuffle:**  
        Если распределение данных неравномерное, добавь `shuffle=True`:
        
        `balanced_rdd = rdd.coalesce(2, shuffle=True)`
        
3. **Используй `repartition` для увеличения партиций.**
    
    - Перед тяжёлыми операциями (`join`, `groupByKey`):
        
        `repartitioned_rdd = rdd.repartition(8)`
        
4. **Синхронизация числа партиций перед `join`.**
    
    - Если количество партиций RDD не совпадает, Spark выполняет shuffle.
    - Приведи оба RDD к одинаковому количеству партиций:
        
        `rdd1 = rdd1.coalesce(4) rdd2 = rdd2.coalesce(4) joined_rdd = rdd1.join(rdd2)`
        

---

#### **Часть 3: Избежание перекоса данных (Data Skew)**

1. **Проблема:**  
    Перекос данных возникает, когда одна или несколько партиций перегружены. Это снижает параллелизм и замедляет выполнение.
    
2. **Когда это важно:**
    
    - Операции с ключами: `join`, `groupByKey`, `reduceByKey`.
3. **Решения:**
    
    - **Добавь "соль" (salting) к ключам:**
        
        `from random import randint salted_rdd = rdd.map(lambda x: (f"{x[0]}_{randint(0, 3)}", x[1])) unsalted_rdd = salted_rdd.map(lambda x: (x[0].split("_")[0], x[1]))`
        
    - **Увеличь количество партиций:**
        
        `repartitioned_rdd = rdd.repartition(8)`
        

---

#### **Часть 4: Практические примеры**

1. **Пример с `repartition`:**
    
    `rdd = sc.parallelize(range(1, 101), numSlices=4) repartitioned_rdd = rdd.repartition(8) print("Число партиций до:", rdd.getNumPartitions()) print("Число партиций после:", repartitioned_rdd.getNumPartitions())`
    
2. **Пример с `coalesce`:**

    `rdd = sc.parallelize(range(1, 101), numSlices=8) coalesced_rdd = rdd.coalesce(4) print("Число партиций до:", rdd.getNumPartitions()) print("Число партиций после:", coalesced_rdd.getNumPartitions())`
    
3. **Проверка распределения:**
    
    `partition_lengths = rdd.glom().map(len).collect() print("Количество элементов в каждой партиции:", partition_lengths)`
    

---

#### **Часть 5: Итоговые рекомендации**

1. Используй `coalesce`, чтобы уменьшить партиции без shuffle.
2. Используй `repartition` для увеличения партиций или равномерного распределения данных.
3. Перед `join` убедись, что партиции синхронизированы.
4. Избегай перекоса данных, добавляя "соль" или увеличивая партиции.
5. Уменьшай количество партиций перед записью на диск:
    
    `rdd.coalesce(8).saveAsTextFile("output")`