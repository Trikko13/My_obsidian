*Spark** **questions**
Q1. Как работает Broadcast? 
A: рассылает копию dataframe на каждый executor. 

Q2. Если использовать broadcast на большой dataframe, что произойдет?
A: Может случится out of memory(OOM), так же broadcast может быть проигнорирован, если он больше trashold'а. (Есть упоминания в лекциях 8 Gb)

Q3. Как оптимизировать Spark pipeline? На что надо смотреть?
A: Во-первых мы смотрим Spark UI в раздел Tasks/jobs, смотрим как распределяются данные по executor'ам. В случае перекоса данных в патрициях, применяем технику соления данных, чтобы данные равномерно распределились по executor'ам.

Можно использовать настройку AQE.

Q4. Какие типы [[Spark JOIN's]]] есть в Apache spark? 
A:
1. Sort Merge Join
2. Shuffle Hash Join
3. Broadcast Hash Join
4. Cartesian Join
5. BroadcastedNested Loop Join
Касательно реализации каждого типа джоина рекомендую погуглить, потому что я в свое время только с 3-4 пояснения понял что да как.


Q5: Как может [[Хранение DataFrame]]  на executor'e? 
A:
.cache() - полностью в памяти
.persist() - memory and Disk - частично в памяти на диске или полностью на диске 
(Смотря что в скобочках указываем)

Q6: Разница между Coalesce и repartion? 
A: coalesce - объединяет множество файлов в один (только уменьшает количество патриций)
Reparation- уменьшает или увеличивает количество патриций
( Обе операции происходят в памяти)

PartitionBy записывает партиции на диск на основе уникальных значений столбцов/столбца.Хранение DataFrame .persist()

Q9: Зачем нужна настройка DynamicAllocation при создании Spark- сессии?
А: Позволяет использовать лишние ресурсы, если есть дополнительные ресурсы на кластере. 

Q11: что делать если возникло Out of memory? 
A: посмотреть как распределяются данные по executor'ам, посмотреть не используется где нибудь .cache большого DF, если не помогает поднимаем память.

Q12: Как [[Ускорить Spark]]приложение ( основное)?

А: Необходимо уменьшать размер передаваемых данных до джоинов, уменьшать количество операций shuffle, так как она больше всего затрагивает времени.


Q13: Где обрабатываются данные? Могут ли хранится на Driver?
А: только на executor'ах. На Driver'е данных нет и не будет.


Q14: Как реализован механизм [[Ленивые вычисления]] (lazy evaluation) ?
A14:
Ленивые вычисления (lazy evaluation) — это ключевой принцип Spark, который откладывает выполнение трансформаций до тех пор, пока не будет вызвано действие.
2 вида операций:
    - transformation - изменение существующего RDD/Dataframe (возвращает другой RDD, например map, filter, join)
    - action - терминальная стадия, приводящая к тому, что накопленные ленивые вычисления начинают свое выполнение (инициация процесса вычисления, например save, count, collect)


Q15.Как Spark считывает данные? Частый вопрос на собеседованиях
Spark обрабатывает данные распределённо и лениво, что делает его мощным инструментом для работы с большими объёмами. 
A15:Вот пошаговый процесс:

1. Мастер-нода (Driver) определяет расположение файла
Когда вы запускаете:
df = spark.read.csv('path/to/file.csv', header=True, inferSchema=True)
Driver обращается к хранилищу, чтобы определить:
Где находится файл (локально, HDFS, S3).
Его размер и структуру.
Как лучше разделить файл на партиции для обработки.

2. Ленивое планирование (Lazy Evaluation)
Spark сразу не выполняет операции, такие как .select() или .filter(). Вместо этого он строит DAG (направленный ацикличный граф) — последовательность шагов для выполнения.
 Данные остаются нетронутыми до вызова действия (Action), такого как .collect() или .write().

3. Разделение данных на партиции
Для файлов в HDFS или S3 Spark использует существующие блоки (обычно 128 MB).
Для локальных файлов он сам делит данные на логические партиции.
 Настройки, например spark.sql.files.maxPartitionBytes, позволяют вручную контролировать размер партиций.

4. Назначение задач Executor-нодам
При вызове Action мастер-нода распределяет задачи:
Каждая Executor-нода получает одну или несколько партиций для обработки.

5. Чтение данных Executor-нодами
Executor-ноды параллельно считывают свои части данных.
 Важно: файл не загружается целиком на одну машину, а обрабатывается частями.

6. Преобразование данных (Transformations)
После чтения Spark выполняет преобразования, например:
.select(), .filter(), .groupBy().
 Эти преобразования ленивые и лишь добавляют шаги в DAG.
 Данные остаются разделёнными на партиции в виде RDD или DataFrame.

7. Выполнение действий (Actions)
Когда вы вызываете Action, Spark запускает DAG и выполняет вычисления:
Локальная обработка: каждая нода обрабатывает свои данные.
Shuffle: перераспределение данных между нодами для объединения, если нужно (например, при groupBy).
Финал: результат возвращается на Driver или сохраняется в хранилище.

8. Завершение вычислений
Результаты объединяются (если требуется) и возвращаются либо записываются.
 
Разница между Transformations и Actions
Transformations: ленивые операции, которые строят план обработки (например, .filter(), .select()).
Actions: запускают выполнение DAG (например, .collect(), .count()).

Почему ленивое выполнение важно?
Ленивый подход Spark позволяет:
Оптимизировать выполнение, исключая ненужные операции.
Сокращать объём данных для обработки, используя фильтры и другие Transformations до выполнения.

Итоги: 
1. Вы запускаете команду чтения, и Driver определяет, где находится файл. 
2. Файл разбивается на партиции. 
3. Executor-ноды параллельно считывают свои части данных. 
4. Данные преобразуются в RDD для распределённой обработки. 
5. Операции выполняются локально, затем объединяются через Shuffle. 
6. Результат возвращается или сохраняется.
