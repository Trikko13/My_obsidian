**DAG โ ััะพ ะพัะธะตะฝัะธัะพะฒะฐะฝะฝัะน ะฐัะธะบะปะธัะตัะบะธะน ะณัะฐั**, ะบะพะฝัะตะฟััะฐะปัะฝะพะต ะฟัะตะดััะฐะฒะปะตะฝะธะต ัะตัะธะธ ะดะตะนััะฒะธะน ะธะปะธ, ะดััะณะธะผะธ ัะปะพะฒะฐะผะธ, ะผะฐัะตะผะฐัะธัะตัะบะฐั ะฐะฑัััะฐะบัะธั ะบะพะฝะฒะตะนะตัะฐ ะดะฐะฝะฝัั (data pipeline).

ะฅะพัั ะพะฑะฐ ัะตัะผะธะฝะฐ, DAG ะธ data pipeline, ะธัะฟะพะปัะทััััั ะฒ ัะฐะทะฝัั ััะตัะฐั, ะพะฝะธ ะฟัะตะดััะฐะฒะปััั ัะพะฑะพะน ะฟะพััะธ ะธะดะตะฝัะธัะฝัะน ะผะตัะฐะฝะธะทะผ. ะ ะดะฒัั ัะปะพะฒะฐั, DAG (ะธะปะธ ะบะพะฝะฒะตะนะตั) ะพะฟัะตะดะตะปัะตั ะฟะพัะปะตะดะพะฒะฐัะตะปัะฝะพััั ััะฐะฟะพะฒ ะฒัะฟะพะปะฝะตะฝะธั ะฒ ะปัะฑะพะผ ะฝะตะฟะพะฒัะพััััะตะผัั ะฐะปะณะพัะธัะผะต.

**1)**ยยยยยยยยยยยยยยย **ะะฐะบะธะต ะพะฟะตัะฐัะพัั ะธัะฟะพะปัะทะพะฒะฐะป?**

**ะะฟะตัะฐัะพัั** ัะฒะปััััั ะพัะฝะพะฒะฝัะผะธ ัััะพะธัะตะปัะฝัะผะธ ะฑะปะพะบะฐะผะธ DAG Airflow. ะญัะพ ะบะปะฐััั, ะบะพัะพััะต ัะพะดะตัะถะฐั ะปะพะณะธะบั ะฒัะฟะพะปะฝะตะฝะธั ะตะดะธะฝะธัะฝะพะน ัะฐะฑะพัั.

ะั ะผะพะถะตัะต ะธัะฟะพะปัะทะพะฒะฐัั ะพะฟะตัะฐัะพัั ะฒ Airflow, ัะพะทะดะฐะฒ ะธั ัะบะทะตะผะฟะปััั ะฒ ะทะฐะดะฐัะฐั. ะะฐะดะฐัะฐ ะพะฟัะตะดะตะปัะตั ัะฐะฑะพัั, ะฒัะฟะพะปะฝัะตะผัั ะพะฟะตัะฐัะพัะพะผ ะฒ ะบะพะฝัะตะบััะต DAG.

ะฅัะบะธ (Hooks) ัะฒะปััััั ะพะดะฝะธะผ ะธะท ะพัะฝะพะฒะฝัั ัััะพะธัะตะปัะฝัั ะฑะปะพะบะพะฒ Airflow. ะะฐ ะฒััะพะบะพะผ ััะพะฒะฝะต ััะบ - ััะพ ะฐะฑัััะฐะบัะธั ะพะฟัะตะดะตะปะตะฝะฝะพะณะพ API, ะบะพัะพััะน ะฟะพะทะฒะพะปัะตั Airflow ะฒะทะฐะธะผะพะดะตะนััะฒะพะฒะฐัั ั ะฒะฝะตัะฝะตะน ัะธััะตะผะพะน. ะฅัะบะธ ะฒัััะพะตะฝั ะฒะพ ะผะฝะพะณะธะต ะพะฟะตัะฐัะพัั, ะฝะพ ะธั ัะฐะบะถะต ะผะพะถะฝะพ ะธัะฟะพะปัะทะพะฒะฐัั ะฝะตะฟะพััะตะดััะฒะตะฝะฝะพ ะฒ ะบะพะดะต DAG.

**BashOperator**ยะธัะฟะพะปัะทัะตััั ะดะปั ะทะฐะฟััะบะฐ ะฟัะพัััั bash ะบะพะผะผะฐะฝะด.

**PythonOperator**ยะฒัะทัะฒะฐะตั ััะฝะบัะธั python, ะพะฟัะตะดะตะปะตะฝะฝัั ัะฐะฝะตะต ะฒ ะฝะฐัะตะผ ะบะพะดะต.

**PostgresOperator** ะฒัะดะฐะตั ะธะฝััััะบัะธั SQL ะดะปั ะฑะฐะทั ะดะฐะฝะฝัั Postgres. ะฃัะตัะฝัะต ะดะฐะฝะฝัะต ะดะปั ะฑะฐะทั ะดะฐะฝะฝัั ััะฐะฝัััั ะฒ ัะพะตะดะธะฝะตะฝะธะธ Airflow ั ะธะผะตะฝะตะผ my_postgres_connection. ะัะปะธ ะฒั ะฟะพัะผะพััะธัะต ะฝะฐ ะบะพะดย[ะพะฟะตัะฐัะพัะฐ Postgres](https://registry.astronomer.io/providers/postgres/modules/postgresoperator), ะพะฝ ะธัะฟะพะปัะทัะตัย[PostgresHook](https://registry.astronomer.io/providers/postgres/modules/postgreshook)ยะดะปั ะฒะทะฐะธะผะพะดะตะนััะฒะธั ั ะฑะฐะทะพะน ะดะฐะฝะฝัั.

## 2)ยยยยยยยยยยยยยยย ะัะธัะพะดะธะปะพัั ะปะธ ะธัะฟะพะปัะทะพะฒะฐัั ัะตะฝัะพัั?

**ะกะตะฝัะพัั** - ััะพ ะพัะพะฑัะน ะฒะธะด ะพะฟะตัะฐัะพัะพะฒ. ะะพะณะดะฐ ะพะฝะธ ะฒัะฟะพะปะฝััััั, ะพะฝะธ ะฟัะพะฒะตัััั, ะฒัะฟะพะปะฝัะตััั ะปะธ ะพะฟัะตะดะตะปะตะฝะฝัะน ะบัะธัะตัะธะน, ะฟัะตะถะดะต ัะตะผ ัะฐะทัะตัะธัั ะฒัะฟะพะปะฝะตะฝะธะต ะฟะพัะปะตะดัััะธั ะทะฐะดะฐั. ะญัะพ ะพัะปะธัะฝัะน ัะฟะพัะพะฑ ะทะฐััะฐะฒะธัั ะพะถะธะดะฐัั ัะฐััั ะทะฐะดะฐั ะฒะฐัะตะณะพ DAG ะทะฐะฒะตััะตะฝะธั ะบะฐะบะพะณะพ-ะปะธะฑะพ ะฒะฝะตัะฝะตะณะพ ะฟัะพัะตััะฐ ะธะปะธ ะฒัะฟะพะปะฝะตะฝะธั ััะปะพะฒะธั.

ยทยยยยยยยยยยยยยยยยยยยย **DateTimeSensor**ยะพะถะธะดะฐะตั ะฟัะพัะพะถะดะตะฝะธั ัะบะฐะทะฐะฝะฝะพะน ะดะฐัั ะธ ะฒัะตะผะตะฝะธ. ะะพะปะตะทะฝะพ, ะบะพะณะดะฐ ะฝัะถะฝะพ ะฒัะฟะพะปะฝััั ะทะฐะดะฐัะธ ะธะท ะพะดะฝะพะณะพ DAG ะฒ ัะฐะทะฝะพะต ะฒัะตะผั;

ยทยยยยยยยยยยยยยยยยยยยย **HttpSensor**ยะพะถะธะดะฐะตั ะดะพัััะฟะฝะพััะธ API;

ยทยยยยยยยยยยยยยยยยยยยย **SqlSensor**ยะพะถะธะดะฐะตั ะฟะพัะฒะปะตะฝะธั ะดะฐะฝะฝัั ะฒ ัะฐะฑะปะธัะต SQL. ะัะธะณะพะดะธััั, ะตัะปะธ ะฝัะถะฝะพ, ััะพะฑั DAG ะพะฑัะฐะฑะฐััะฒะฐะป ะดะฐะฝะฝัะต ะฟะพ ะผะตัะต ะธั ะฟะพัััะฟะปะตะฝะธั ะฒ ะฑะฐะทั ะดะฐะฝะฝัั.

**3)**ยยย **ะะฐะบ ัะตััะธัะพะฒะฐะป ะดะฐะณะธ?**

ะะปั ัะตััะธัะพะฒะฐะฝะธั ะดะฐะณะพะฒ ะฒ Apache Airflow ะผะพะถะฝะพ ะธัะฟะพะปัะทะพะฒะฐัั ะผะพะดัะปั **unittest** ะฒ ัะพัะตัะฐะฝะธะธ ั ะบะปะฐััะพะผ **DagBag**. ะะพั ะฟัะธะผะตั ัะพะณะพ, ะบะฐะบ ะฒั ะผะพะถะตัะต ะฝะฐะฟะธัะฐัั ัะตัั ะดะปั ะฒะฐัะตะณะพ ะดะฐะณะฐ:

**ะกะพะทะดะฐะนัะต ะฝะพะฒัะน ัะฐะนะป** ั ัะฐััะธัะตะฝะธะตะผ .py ะดะปั ะฒะฐัะตะณะพ ัะตััะฐ ะดะฐะณะฐ.

**ะะผะฟะพััะธััะนัะต** ะฝะตะพะฑัะพะดะธะผัะต ะผะพะดัะปะธ:

import **unittest**

from airflow.models import **DagBag**

**ะกะพะทะดะฐะนัะต** **ะบะปะฐัั** **ัะตััะฐ**, ะบะพัะพััะน ะฝะฐัะปะตะดัะตััั ะพั **unittest.TestCase**:

class TestMyDag(unittest.TestCase):

ยยย def setUp(self):

ยยยยยยย self.dagbag = DagBag()

ยยย def test_dag_loaded(self):

ยยยยยยย dag_id = 'my_dag_id'

ยยยยยยย dag = self.dagbag.get_dag(dag_id)

ยยยยยยย self.assertIsNotNone(dag)

ะ ะผะตัะพะดะต **setUp** ะธะฝะธัะธะฐะปะธะทะธััะนัะต ัะบะทะตะผะฟะปัั **DagBag**, ะบะพัะพััะน ะฑัะดะตั ะทะฐะณััะถะฐัั ะฒัะต ะดะฐะณะธ ะธะท ะฒะฐัะตะณะพ ะฟัะพะตะบัะฐ.

ะ ะผะตัะพะดะต **test_dag_loaded** ะฟัะพะฒะตัััะต, ััะพ ะฒะฐั ะดะฐะณ ะฑัะป ััะฟะตัะฝะพ ะทะฐะณััะถะตะฝ ะธะท **DagBag**.

**ะะฐะฟัััะธัะต** ะฒะฐั ัะตัั ั ะฟะพะผะพััั ะบะพะผะฐะฝะดั **python -m unittest <ะธะผั_ัะฐะนะปะฐ_ัะตััะฐ>**. ะะฐะฟัะธะผะตั, **python -m unittest test_my_dag.py**.

ะัะธ ะทะฐะฟััะบะต ัะตััะฐ, ะพะฝ ะทะฐะณััะทะธั ะฒัะต ะดะฐะณะธ ะธะท ะฒะฐัะตะณะพ ะฟัะพะตะบัะฐ ะธ ะฟัะพะฒะตัะธั, ััะพ ะฒะฐั ะดะฐะณ ะฑัะป ััะฟะตัะฝะพ ะทะฐะณััะถะตะฝ. ะั ัะฐะบะถะต ะผะพะถะตัะต ะดะพะฑะฐะฒะธัั ะดะพะฟะพะปะฝะธัะตะปัะฝัะต ัะตััั ะดะปั ะฟัะพะฒะตัะบะธ ะดััะณะธั ะฐัะฟะตะบัะพะฒ ะฒะฐัะตะณะพ ะดะฐะณะฐ, ัะฐะบะธั ะบะฐะบ ะฝะฐะปะธัะธะต ะพะฟะตัะฐัะพัะพะฒ, ะฟัะฐะฒะธะปัะฝะพััั ะทะฐะฒะธัะธะผะพััะตะน ะธ ั.ะด.


### ะะพะฟัะพั: "ะะดะต ัะฐะทะฒะพัะฐัะธะฒะฐะปะธ Airflow, ะพัะบัะดะฐ ะธ ะบัะดะฐ ะณะฝะฐะปะธ ะดะฐะฝะฝัะต?"
๐ **ะขั ัะบะฐะทะฐะป, ััะพ ะธะท HDFS ะธ API โ ะฒ DWH ะฝะฐ Hadoop**.

๐น **ะะพััะตะบัะฝะพ ะปะธ?**

- **HDFS** โ ะะ, ะฝะพ **ะพะฑััะฝะพ ะดะฐะฝะฝัะต ะธะท HDFS ะฝะต ััะธัะฐัััั DWH**. Hadoop โ ัะบะพัะตะต **Data Lake**.
- **API โ DWH** โ ัะพะถะต ะฒะพะทะผะพะถะฝะพ, ะฝะพ ะพะฑััะฝะพ API-ะดะฐะฝะฝัะต ะธะดัั ะฒ **ััะตะนะดะถะธะฝะณ (staging)** ะฟะตัะตะด DWH.
- **ะะฑััะฝะพ DWH ัะฐะทะฒะพัะฐัะธะฒะฐะตััั ะฒ Greenplum, Snowflake, Redshift**, ะฝะพ ะธะฝะพะณะดะฐ Hadoop + Hive ะผะพะณัั ะธัะฟะพะปัะทะพะฒะฐัััั ะดะปั OLAP.

๐น **ะะฐะบ ะปัััะต ะฑัะปะพ ะพัะฒะตัะธัั?**  
๐ **ะัะฒะตั:**

> Airflow ะฑัะป ัะฐะทะฒะตัะฝัั ะฝะฐ **ัะตัะฒะตัะต Linux ะฒ ะบะปะฐััะตัะต Hadoop**.  
> ะะฐะฝะฝัะต ะฑัะฐะปะธ **ะธะท HDFS, API, Kafka**, ะทะฐะณััะถะฐะปะธ ะฒ **DWH (Greenplum / Snowflake / Hive)**.

๐ **ะะพััะตะบัะฝัะน ััะตะบ DWH:**

- ะััะพัะฝะธะบะธ: **HDFS, API, Kafka, Clickhouse, PostgreSQL**
- ะัะพะผะตะถััะพัะฝะพะต ััะฐะฝะตะฝะธะต: **Staging ะฒ Data Lake (HDFS / S3)**
- DWH: **Greenplum / Snowflake / Redshift**

๐ก **ะกะพะฒะตั:** ะัะปะธ ะฝะต ัะฒะตัะตะฝ, ััะพัะฝะธ:

> "ะะฐะฒะธัะธั ะพั ะฐััะธัะตะบัััั ะบะพะผะฟะฐะฝะธะธ: ะณะดะต-ัะพ ะธัะฟะพะปัะทััั Hadoop + Hive ะบะฐะบ DWH, ะฐ ะณะดะต-ัะพ Greenplum / Snowflake."

### ะะพะฟัะพั: "ะะฐะบะธะต ะฑะธะฑะปะธะพัะตะบะธ ะฝัะถะฝั ะดะปั ัะฐะฑะพัั ั Hadoop?"
๐ **ะขั ัะบะฐะทะฐะป, ััะพ ะฟะธัะตัั `hdfs.read.parquet('sentence')`, ะฝะพ ัะตะฑะต ัะบะฐะทะฐะปะธ, ััะพ ััะพ ะฝะตะฒะตัะฝะพ.**

๐น **ะะฐะบะธะต ะฑะธะฑะปะธะพัะตะบะธ ะดะตะนััะฒะธัะตะปัะฝะพ ะธัะฟะพะปัะทััััั?**  
โ **PyArrow** (`pyarrow.fs.HadoopFileSystem`)  
โ **hdfs3 / fsspec** (ัะฐะฑะพัะฐ ั HDFS)  
โ **Pyspark** (`spark.read.parquet()`)

๐น **ะะฐะบ ะฟัะฐะฒะธะปัะฝะพ ัะธัะฐัั Parquet ะธะท HDFS?**


`from pyspark.sql import SparkSession  
`spark = SparkSession.builder.appName("ReadHDFS").getOrCreate()

`df = spark.read.parquet("hdfs://namenode:9000/data/file.parquet") df.show()`

๐ **ะัะฒะพะด:**

- ะะปั HDFS ะฒ Spark โ `spark.read.parquet("hdfs://...")`
- ะะปั Pandas โ ะปัััะต **ะธัะฟะพะปัะทะพะฒะฐัั `pyarrow` ะธะปะธ `fsspec`**
- `hdfs.read.parquet('sentence')` **ะฝะตะฒะตัะฝะพ**, ั.ะบ. Pandas ะฝะต ัะผะตะตั ัะฐะฑะพัะฐัั ะฝะฐะฟััะผัั ั HDFS
### ะะพะฟัะพั: "ะะพะณะดะฐ ะฟะพะฝะธะถะฐัั ะบะพะปะธัะตััะฒะพ ะฟะฐััะธัะธะน?"
๐ **ะขั ัะบะฐะทะฐะป "ะฟัะธ ะทะฐะฟะธัะธ ัะฐะนะปะฐ", ััะพ ัะฐััะธัะฝะพ ะฒะตัะฝะพ, ะฝะพ ะฝะต ะพะฑัััะฝะธะป ะบัะธัะตัะธะธ.**

โ **ะะพะฝะธะถะฐัั ะฟะฐััะธัะธะธ (`coalesce()`) ะฝัะถะฝะพ, ะตัะปะธ:**  
1๏ธโฃ **ะคะฐะนะปั ัะปะธัะบะพะผ ะผะฐะปะตะฝัะบะธะต** โ ั.ะบ. ะผะฝะพะณะพ ะผะตะปะบะธั ัะฐะนะปะพะฒ **ะทะฐะผะตะดะปััั ัะฐะฑะพัั HDFS ะธ Spark**.  
2๏ธโฃ **ะกะปะธัะบะพะผ ะผะฝะพะณะพ ัะฐะนะปะพะฒ ะฝะฐ ะทะฐะฟะธัั** โ ััะพ ัะฝะธะถะฐะตั ะฟัะพะธะทะฒะพะดะธัะตะปัะฝะพััั.

๐น **ะัะธะผะตั: ะฃะผะตะฝััะฐะตะผ ะฟะฐััะธัะธะธ ะฟะตัะตะด ะทะฐะฟะธััั (ััะพะฑั ะฑัะปะพ ะผะตะฝััะต ัะฐะนะปะพะฒ):**

`df = df.coalesce(1)  # ะะฑัะตะดะธะฝัะตะผ ะฟะฐััะธัะธะธ df.write.parquet("hdfs://namenode:9000/output/")`

๐ **ะะพัะตะผั?**

- ะัะปะธ ะบะฐะถะดะฐั ะฟะฐััะธัะธั ะฟะธัะตั ะพัะดะตะปัะฝัะน ัะฐะนะป, ัะพ 1000 ะฟะฐััะธัะธะน = 1000 ัะฐะนะปะพะฒ โ ะผะตะดะปะตะฝะฝะพ!
- `coalesce(1)` โ **ัะพะทะดะฐัั 1 ัะฐะนะป, ะฝะพ ะผะตะดะปะตะฝะฝะตะต ะฒัะฟะพะปะฝัะตััั**.
#### ะะพะฟัะพั: "ะงัะพ ัะฐะบะพะต SCD?"
**ะขั ะฝะฐะทะฒะฐะป `SCD0`, `SCD1`, `SCD2`, ะฝะพ ะทะฐะฟััะฐะปัั ะฒ ัะฐะฑะปะธัะฐั.**

โ **Slowly Changing Dimensions (SCD) โ ะผะตัะพะด ััะฐะฝะตะฝะธั ะธััะพัะธัะตัะบะธั ะดะฐะฝะฝัั ะฒ DWH.**

|**ะขะธะฟ**|**ะะฟะธัะฐะฝะธะต**|**ะะฐะบ ัะตะฐะปะธะทัะตััั?**|
|---|---|---|
|**SCD 0**|ะะตั ะธััะพัะธัะฝะพััะธ, ะดะฐะฝะฝัะต ะฟัะพััะพ ะพะฑะฝะพะฒะปััััั|`UPDATE`|
|**SCD 1**|ะะตัะตะทะฐะฟะธััะฒะฐะตะผ ะดะฐะฝะฝัะต ะฑะตะท ััะฐะฝะตะฝะธั ะธััะพัะธะธ|`UPDATE` (ะฑะตะท ะฒะตััะธะน)|
|**SCD 2**|ะะพะฑะฐะฒะปัะตะผ ะฝะพะฒัั ัััะพะบั ะดะปั ะบะฐะถะดะพะน ะฒะตััะธะธ ะทะฐะฟะธัะธ|`valid_from`, `valid_to`|
|**SCD 3**|ะะพะฑะฐะฒะปัะตะผ ะบะพะปะพะฝะบั ั "ะฟัะตะดัะดััะธะผ ะทะฝะฐัะตะฝะธะตะผ"|`prev_value`|

๐น **ะัะธะผะตั SCD 2 (ะธััะพัะธะทะฐัะธั ะฒ ะพะดะฝะพะน ัะฐะฑะปะธัะต):**

sql

ะะพะฟะธัะพะฒะฐัั

`CREATE TABLE customers (     id INT PRIMARY KEY,     name VARCHAR,     address VARCHAR,     valid_from DATE,     valid_to DATE NULL );`

๐ **ะัะฒะพะด:**

- **SCD โ ะพัะดะตะปัะฝัะต ัะฐะฑะปะธัั** โ ะธััะพัะธัะฝะพััั ะฒะตะดัััั **ะฒ ัะตั ะถะต ัะฐะฑะปะธัะฐั, ะฝะพ ั ะดะพะฟ. ะบะพะปะพะฝะบะฐะผะธ**.


### ะะพะฟัะพั: "ะะฐะบ ัะฐะฑะพัะฐะตั `broadcast join`?"

**ะขั ัะบะฐะทะฐะป, ััะพ "ะผะฐะปะฐั ัะฐะฑะปะธัะฐ ะบะพะฟะธััะตััั ะฝะฐ ะบะปะฐััะตัะฐ", ััะพ ัะฐััะธัะฝะพ ะฒะตัะฝะพ, ะฝะพ ะปัััะต ัะพัะฝะตะต.**

โ **ะะฐะบ ััะพ ัะฐะฑะพัะฐะตั?**

- **Spark ะบะพะฟะธััะตั ะผะฐะปะตะฝัะบัั ัะฐะฑะปะธัั (`< 100MB`) ะฝะฐ ะฒัะต ัะทะปั**.
- ะฃ ะบะฐะถะดะพะณะพ executor'ะฐ ะตััั ะบะพะฟะธั ััะพะน ัะฐะฑะปะธัั โ **ััะบะพััะตั join**.

๐น **ะัะธะผะตั `broadcast join` ะฒ Spark:**



`from pyspark.sql.functions import broadcast  

`big_df = spark.read.parquet("hdfs://big_table.parquet") 
`small_df = spark.read.csv("hdfs://small_table.csv")  

`df_joined = big_df.join(broadcast(small_df), "id")  # ะะฟัะธะผะธะทะธัะพะฒะฐะฝะฝัะน join`

๐ **ะะพัะตะผั ััะพ ััะบะพััะตั ัะฐะฑะพัั?**

- ะะตะท `broadcast()` Spark ะดะตะปะฐะตั **shuffle join** (ะผะตะดะปะตะฝะฝัะน, ั.ะบ. ะฝัะถะฝะพ ะฟะตัะตะผะตัะฐัั ะดะฐะฝะฝัะต).
- `broadcast()` ัะฑะธัะฐะตั shuffle ะธ **ััะบะพััะตั join ะฒ ัะฐะทั**.