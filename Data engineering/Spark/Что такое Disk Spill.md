**Disk Spill** происходит, когда **Executor** исчерпывает доступную память для обработки данных (например, для shuffle, join, или сортировки). Тогда Spark начинает временно записывать данные на диск.

### **Связь с Shuffle Memory:**

- **Shuffle Memory** — это часть **Execution Memory**, где данные хранятся во время операций shuffle.
- Если **Shuffle Memory** переполняется, данные записываются на диск (**Disk Spill**). Это значительно медленнее, чем работа в памяти, но позволяет продолжить выполнение задачи.
### **Категория памяти для Disk Spill:**

**Disk Spill** не относится к одной из стандартных категорий памяти (On-Heap, Off-Heap, Overhead). Это **внешняя память**, которая использует дисковое пространство узла.

- Для Disk Spill используются временные файлы на диске узла, где запущен Executor.
- Эти файлы создаются в директориях, указанных параметрами:
    `spark.local.dir`

### **Когда происходит Disk Spill?**

1. **Execution Memory заполнена:**
    
    - При выполнении shuffle или сортировки данных, если нет свободной памяти для временных вычислений.
2. **Storage Memory заполнена:**
    
    - Если Spark пытается закэшировать данные, но для них нет места.
3. **Off-Heap Memory заполнена:**
    
    - Если включена и активно используется, но данных больше, чем выделено в Off-Heap.
### **Пример:**

#### Если **Shuffle Memory** заполнена:


`from pyspark.sql import SparkSession  

`spark = SparkSession.builder \     .appName("DiskSpillExample") \     .config("spark.executor.memory", "2g") \       .config("spark.memory.fraction", "0.6") \     .config("spark.local.dir", "/tmp/spark-temp") \     .getOrCreate()  

`# Создаём DataFrame с большими данными 
`data = [(i, i % 1000) for i in range(10000000)] 
`df = spark.createDataFrame(data, ["id", "group"])  

`# Принудительно вызываем shuffle через groupBy 
`result = df.groupBy("group").count() 
`result.show()`

Исследования и лучшие практики показывают, что оптимизация перетасовки (shuffle) и предотвращение переполнения на диск (disk spill) необходимы для повышения производительности Spark, поскольку перетасовки могут вызывать сетевые накладные расходы, а переполнения замедляют обработку из-за медленного ввода-вывода на диск.

#### Ключевые стратегии по сокращению перетасовки

- **Оптимизация партиций**: Установите spark.sql.shuffle.partitions выше значения по умолчанию (200) для больших данных, чтобы сбалансировать нагрузку, но избегайте чрезмерных значений, чтобы предотвратить мелкие задачи; используйте Adaptive Query Execution (AQE) для динамических корректировок.
- **Использование широковещательных соединений**: Для соединений с маленькими наборами данных включите автоматические широковещательные соединения через spark.sql.autoBroadcastJoinThreshold, чтобы исключить перетасовку с одной стороны.
- **Применение фильтров на ранних этапах**: Отправляйте предикаты к источникам данных, чтобы минимизировать объем данных перед перетасовкой.
- **Обработка перекоса данных**: Используйте солинг или оптимизацию перекоса в AQE для равномерного распределения данных и снижения неравномерных нагрузок на перетасовку.
- **Выбор эффективных операций**: Предпочтите узкие трансформации широким, и используйте подсказки coalesce для объединения партиций без полной перетасовки.

#### Ключевые стратегии по избежанию переполнения на диск

- **Увеличение ресурсов памяти**: Повысьте spark.executor.memory и настройте spark.memory.fraction (по умолчанию 0.6), чтобы выделить больше места для выполнения и хранения, предотвращая переполнение.
- **Улучшение партиционирования**: Используйте больше партиций, чтобы держать данные отдельных задач достаточно маленькими для размещения в памяти, снижая риски переполнения во время операций.
- **Устранение перекоса данных**: Внедряйте техники солинга для баланса размеров партиций, поскольку перекос данных часто вызывает переполнения в перегруженных задачах.
- **Использование эффективной сериализации**: Перейдите на сериализатор Kryo для компактного представления данных, минимизируя объем памяти во время перетасовок и вычислений.
- **Мониторинг и настройка**: Проверьте UI Spark на метрики переполнения и скорректируйте конфигурации, такие как spark.memory.storageFraction, чтобы приоритизировать память выполнения.

**Общие соображения**: Эти подходы могут существенно улучшить эффективность заданий, но их эффективность зависит от конкретной нагрузки и конфигурации кластера — всегда тестируйте настройки в вашей среде. Если тема вызывает споры, такие как оптимальные значения памяти, исследования склоняются к динамическим настройкам через AQE для адаптации.

**Дополнительные ресурсы**: Для углубленного изучения обратитесь к документации Apache Spark[](https://spark.apache.org/docs/latest/sql-performance-tuning.html) или сообществам вроде Stack Overflow.

---

В Apache Spark операции перетасовки и переполнения на диск являются распространенными узкими местами, которые могут снижать производительность в распределенной обработке данных. Перетасовка относится к перераспределению данных по партициям во время широких трансформаций, таких как соединения, groupBy или агрегации, часто включающих сетевой ввод-вывод и сериализацию. Переполнение на диск происходит, когда данные в памяти превышают доступный RAM, заставляя Spark записывать промежуточные результаты на диск, что замедляет выполнение из-за более медленных операций ввода-вывода. Этот всесторонний гид опирается на официальную документацию Spark и анализы экспертов, чтобы объяснить причины, мониторинг и стратегии оптимизации для обоих проблем. Мы охватим определения, коренные причины, практические техники с примерами кода, параметры конфигурации и лучшие практики, обеспечивая глубокое понимание для реализации в реальных заданиях Spark.

#### Понимание перетасовки в Spark

Перетасовка — это механизм Spark для реорганизации данных по партициям RDD или DataFrame, обычно запускаемый операциями, требующими группировки по ключу (например, reduceByKey, join). Она включает две фазы: map-side (запись промежуточных данных) и reduce-side (получение и слияние). Хотя она необходима, чрезмерная перетасовка увеличивает сетевой трафик, использование CPU и потенциал для переполнений.

Причины высокого overhead перетасовки включают:

- Широкие трансформации, которые перераспределяют все данные.
- Неоптимальное количество партиций, приводящее к неравномерному распределению данных.
- Перекос данных, где определенные ключи доминируют, вызывая несбалансированные задачи.

Для мониторинга перетасовки используйте вкладку Stages в UI Spark: Ищите высокие метрики "Shuffle Write" и "Shuffle Read", которые указывают на объем перемещения данных. Высокие значения предполагают возможности оптимизации.

#### Техники по сокращению перетасовки

Минимизация перетасовки начинается с оптимизации запросов и эффективной обработки данных. Ключевые стратегии включают:

1. **Настройка партиций**: Установите spark.sql.shuffle.partitions на значение, которое балансирует параллелизм без создания слишком многих мелких задач. Для маленьких данных уменьшите его; для больших увеличьте и позвольте AQE объединять их после перетасовки.
    
    - Пример: В Spark SQL настройте через конфигурацию:
        
        text
        
        ```
        spark.conf.set("spark.sql.shuffle.partitions", "100")
        ```
        
    - С AQE (включенным через spark.sql.adaptive.enabled = true), используйте высокое начальное количество партиций и позвольте Spark динамически объединять их через spark.sql.adaptive.coalescePartitions.enabled.
2. **Широковещательные соединения**: Рассылайте маленькие таблицы на все исполнители, избегая перетасовки для этой стороны. Это идеально, когда одна таблица помещается в память (например, <10MB по умолчанию).
    
    - Конфигурация: Настройте spark.sql.autoBroadcastJoinThreshold для контроля автоматической рассылки.
    - Пример подсказки в SQL:
        
        text
        
        ```
        SELECT /*+ BROADCAST(small_table) */ * FROM large_table JOIN small_table ON large_table.key = small_table.key
        ```
        
    - В Scala/Python:
        
        text
        
        ```
        import org.apache.spark.sql.functions.broadcast
        largeTable.join(broadcast(smallTable), "key")
        ```
        
3. **Отправка фильтров и раннее сокращение данных**: Применяйте фильтры близко к источнику данных, чтобы уменьшить объем перед перетасовкой.
    
    - Для партиционированных данных (например, Parquet) используйте предикаты, которые обрезают партиции.
    - Конфигурации вроде spark.sql.files.maxPartitionBytes (по умолчанию 128MB) помогают контролировать размеры входных партиций.
4. **Подсказки coalesce и repartition**: Используйте подсказки для контроля выходных партиций без полной перетасовки.
    
    - Пример:
        
        text
        
        ```
        SELECT /*+ COALESCE(5) */ * FROM table
        ```
        
5. **Соединение с сохранением партиций хранилища (SPJ)**: Для совместимых источников данных, таких как Iceberg, включите бакетирование для совместного партиционирования таблиц и исключения перетасовок.
    
    - Включение: spark.sql.sources.v2.bucketing.enabled = true
6. **Эффективная сериализация**: Используйте Kryo вместо Java для компактных данных перетасовки.
    
    - Конфигурация: spark.serializer = org.apache.spark.serializer.KryoSerializer

Таблица, суммирующая конфигурации, связанные с перетасовкой:

|Конфигурация|Значение по умолчанию|Назначение|Влияние на перетасовку|
|---|---|---|---|
|spark.sql.shuffle.partitions|200|Устанавливает количество партиций перетасовки|Балансирует перемещение данных; слишком высокое/низкое увеличивает overhead|
|spark.sql.autoBroadcastJoinThreshold|10MB|Порог для авто-широковещательных соединений|Снижает перетасовки для маленьких соединений|
|spark.sql.adaptive.enabled|true (с 3.2)|Включает оптимизации времени выполнения|Динамически снижает этапы и перетасовки|
|spark.shuffle.compress|true|Сжимает выход перетасовки|Снижает ввод-вывод во время передачи данных|

#### Понимание переполнения на диск в Spark

Переполнение на диск происходит, когда память выполнения или хранения исчерпана, и Spark сериализует и записывает данные на диск. Память выполнения (для вычислений) может вытеснять из памяти хранения (для кэширования), но не наоборот. Переполнения снижают производительность, вводя задержки ввода-вывода на диск.

Причины:

- Большие промежуточные данные от перетасовок/соединений.
- Недостаточная память исполнителя.
- Перекос данных, приводящий к oversized партициям.
- Чрезмерное кэширование или параллельные задачи, интенсивные по памяти.

Мониторинг через UI Spark: В Stages проверьте столбцы "Spill (Memory)" и "Spill (Disk)" — ненулевые значения указывают на переполнение. Сортируйте по длительности, чтобы выявить проблемные этапы.

#### Техники по избежанию переполнения на диск

Предотвращение фокусируется на эффективности памяти и сбалансированных нагрузках:

1. **Увеличение выделения памяти**: Масштабируйте память исполнителя, чтобы поместить данные.
    
    - Конфигурация: spark.executor.memory (например, 4g); настройте spark.memory.fraction для выделения больше unified памяти.
    - Для GC: Используйте флаги вроде -XX:+PrintGCDetails для мониторинга и корректировки размеров young/old поколений.
2. **Лучшее партиционирование**: Больше партиций держат фрагменты данных маленькими.
    
    - Пример: Repartition DataFrame: df.repartition(100)
    - Настройте spark.sql.files.maxPartitionBytes для чтений входа.
3. **Обработка перекоса данных с солингом**: Добавляйте случайные соли к ключам для перераспределения данных.
    
    - Пример для соединения:
        
        text
        
        ```
        val saltedDF = df.withColumn("salt", rand() % 10)
        otherDF.join(saltedDF, Seq("key", "salt"))
        ```
        
4. **Эффективная сериализация и сжатие**: Kryo снижает объем памяти.
    
    - Регистрируйте классы: conf.registerKryoClasses(Array(classOf[MyClass]))
5. **Off-Heap и продвинутая настройка памяти**: Хотя по умолчанию on-heap, исследуйте off-heap для больших наборов (через spark.memory.offHeap.enabled).
    
6. **AQE для обработки перекоса и объединения**: Включите обработку перекоса соединений.
    
    - Конфигурация: spark.sql.adaptive.skewJoin.enabled = true

Таблица стратегий предотвращения переполнения:

|Конфигурация|Значение по умолчанию|Назначение|Влияние на переполнение|
|---|---|---|---|
|spark.executor.memory|1g|Куча на исполнителя|Прямо увеличивает доступную память|
|spark.memory.fraction|0.6|Доля unified памяти|Балансирует выполнение/хранение для предотвращения вытеснения/переполнения|
|spark.memory.storageFraction|0.5|Доля хранения в unified|Приоритизирует кэширование без переполнения выполнения|
|spark.sql.adaptive.skewJoin.skewedPartitionFactor|5.0|Порог обнаружения перекоса|Разделяет перекосные партиции, избегая oversized задач|
|spark.kryoserializer.buffer.max|64m|Максимальный буфер Kryo|Обрабатывает большие объекты без переполнения|

#### Лучшие практики и мониторинг

- **Итеративное тестирование**: Начните с маленьких данных, мониторьте UI и масштабируйте конфигурации.
- **Широкое использование AQE**: С Spark 3.0 оно динамически оптимизирует перетасовки и переполнения.
- **Форматы данных**: Предпочтите Parquet/Avro для сжатия, снижая размер перетасовки.
- **Размер кластера**: Стремитесь к 2-3 задачам на ядро; используйте динамическое выделение.
- **Когда масштабировать**: Если оптимизации не помогают, добавьте узлы — но приоритизируйте настройку сначала.

Применяя эти стратегии, вы можете добиться более быстрых и надежных заданий Spark с минимальной перетасовкой и без переполнений на диск.