Эти методы изменяют количество партиций в RDD.

#### **1.1. Разница между `repartition` и `coalesce`:**

| Метод             | Описание                                                                                  | Когда использовать                                                                                                        |
| ----------------- | ----------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------- |
| **`coalesce`**    | Уменьшает количество партиций. Старается избежать shuffle, если явно не указать параметр. | Когда нужно уменьшить число партиций перед дорогостоящей операции (например перед, `join`).                               |
| **`repartition`** | Увеличивает или уменьшает количество партиций. Вызывает shuffle (перемешивание данных).   | Когда нужно перераспределить данные для равномерной обработки или увеличить количество партиций (например после, `join`). |
#### **Ключевые моменты:**

- **Shuffle в `repartition`:** Spark перемещает данные между партициями, чтобы перераспределить их.
- **Без shuffle в `coalesce`:** Spark просто объединяет существующие партиции.

1.2. Пример: `repartition`
`rdd = sc.parallelize([1, 2, 3, 4, 5, 6, 7, 8, 9], numSlices=2) 
`# Увеличим число партиций до 4 
`repartitioned_rdd = rdd.repartition(4) 

`print("Число партиций до:", rdd.getNumPartitions()) print("Число партиций после:", repartitioned_rdd.getNumPartitions())

## Best practices 
Вот несколько **best practices** для работы с партициями в Spark, которые помогут эффективно использовать `coalesce`, `repartition` и минимизировать проблемы с производительностью:

### **1. Всегда проверяйте размер данных перед операцией**

- **Маленькие данные:**  
    Если объём данных небольшой, не стоит использовать много партиций. Например, для набора данных объёмом 10 МБ достаточно 2–4 партиций.
- **Большие данные:**  
    Для больших наборов данных используйте количество партиций, которое позволит избежать больших перекосов (например, 1 партиция на 128 МБ данных).

#### **Best practice:**

Перед тем как менять количество партиций, анализируйте данные с помощью:
`rdd.glom().map(len).collect()  # Показывает количество элементов в каждой партиции

Вот пример кода:

`Создаём RDD с числами от 1 до 100, распределяя их на 4 партиции 
`rdd = sc.parallelize(range(1, 101), numSlices=4) 

`# Используем glom() для анализа данных в каждой партиции partitions = rdd.glom().collect() # glom() собирает все элементы каждой партиции в виде списка 

`# Выводим содержимое каждой партиции 
`for i, partition in enumerate(partitions): 
	`print(f"Партиция {i}: {partition}") 
	
`# Анализируем количество элементов в каждой партиции partition_lengths = rdd.glom().map(len).collect() print("Количество элементов в каждой партиции:", partition_lengths)`

### **2. Используйте `coalesce` для уменьшения партиций**

- Применяйте **`coalesce`**, чтобы уменьшить партиции после операций, которые увеличивают их количество (например, `textFile` или `filter`), но только если shuffle не нужен.  
    **Пример:**  
    После фильтрации:
- `filtered_rdd = rdd.filter(lambda x: x > 10).coalesce(2)`

#### **Best practice:**

- **Без shuffle:**  
    Используйте `coalesce` для уменьшения партиций только тогда, когда перекос данных не критичен.
- **С shuffle:**  
    Если данные перекошены, укажите `shuffle=True`, чтобы перераспределить их равномерно:
`rdd.coalesce(2, shuffle=True)`

### **3. Используйте `repartition` для увеличения партиций**

- Если вы хотите увеличить количество партиций, всегда используйте `repartition`. Он вызывает shuffle и равномерно распределяет данные.  
    **Пример:**  
    Увеличение партиций перед тяжёлой операцией:
    `repartitioned_rdd = rdd.repartition(8)`
    

#### **Best practice:**

- Применяйте `repartition` для:
    - Увеличения параллелизма перед тяжёлыми вычислениями (`reduceByKey`, `join`, `groupByKey`).
    - Равномерного распределения данных после операций, таких как `join`.

### **Вывод**

- Уменьшение партиций с помощью `coalesce` — **перед `join`, если RDD маленький**. Чтобы оптимизировать shuffle
- Увеличение партиций с помощью `repartition` — **для больших RDD перед `join`, чтобы увеличить параллелизм**.
- Поддерживай одинаковое количество партиций у обоих RDD.
### **4. Синхронизация числа партиций перед `join`**

Когда два RDD или DataFrame объединяются с помощью `join`, важно, чтобы их партиции были синхронизированы.

- Если у RDD разное количество партиций, Spark выполнит shuffle, что может замедлить процесс.  
    **Решение:** Приведите их к одинаковому числу партиций:
`rdd1 = rdd1.coalesce(4) 
`rdd2 = rdd2.coalesce(4) 
`joined_rdd = rdd1.join(rdd2)

### **5. Предотвращение перекоса данных (Data Skew)**

- **Перекос данных:** Когда одна или несколько партиций содержат гораздо больше данных, чем остальные.  
    Это может произойти после `reduceByKey`, `join`, или других операций с ключами.
#### Пример:

Допустим, данные выглядят так:
`data = [("a", 1), ("a", 2), ("a", 3), ..., ("b", 1), ("c", 1)]`

- Если ключ `"a"` встречается в 90% случаев, то он попадёт в одну партицию:
    `hash("a") % numPartitions → всегда одна и та же партиция`
#### **Когда концентрация ключей особенно важна?**
### При операциях:

- **`join`:**  
    Spark должен переместить данные с одинаковыми ключами в одну партицию, чтобы выполнить соединение. Если ключ встречается часто, большая часть данных окажется в одной партиции.
    
- **`groupByKey`:**  
    Все значения с одинаковым ключом перемещаются в одну партицию для группировки.
    
- **`reduceByKey`:**  
    Spark агрегирует данные с одинаковыми ключами в пределах одной партиции.
#### **Как избежать перекоса:**

1. Увеличьте число партиций после `join`:
    `joined_rdd = rdd1.join(rdd2).repartition(8)`
    
2. Добавьте "случайные" ключи, чтобы избежать избыточной концентрации данных в одной партиции:
    `skewed_rdd = rdd.map(lambda x: ((x[0], random.randint(0, 3)), x[1]))`
3. Добавляем случайное число к ключу, чтобы распределить данные равномерно.
	`salted_rdd = rdd.map(lambda x: (f"{x[0]}_{randint(0, 3)}", x[1]))`

	Для последующей обработки удаляем "соль":
	`unsalted_rdd = salted_rdd.map(lambda x: (x[0].split("_")[0], x[1]))

## Пример: работа с перекосом данных

#### Исходные данные:
`data = [("a", 1), ("a", 2), ("a", 3), ..., ("b", 1), ("c", 1)] rdd = sc.parallelize(data)`

#### 5.1. Добавляем соль:
`from random import randint salted_rdd = rdd.map(lambda x: (f"{x[0]}_{randint(0, 3)}", x[1]))`

#### 5.2. Выполняем операцию (например, `reduceByKey`):
`reduced_rdd = salted_rdd.reduceByKey(lambda a, b: a + b)`

#### 5.3. Убираем соль:
`unsalted_rdd = reduced_rdd.map(lambda x: (x[0].split("_")[0], x[1]))`


### **6. Оценивайте распределение данных после операции**

После выполнения тяжёлых операций, таких как `groupByKey` или `join`, проверьте распределение данных:

`rdd.glom().map(len).collect()`

Если одна партиция содержит много данных, используйте:

- **`repartition`**, чтобы распределить данные равномерно.
- Или настройте количество партиций на этапе вызова операции (например, `join(numPartitions=8)`).

### **7. Учитывайте размер блока при работе с HDFS**

- Если данные загружаются из HDFS или другого источника, количество партиций по умолчанию соответствует количеству блоков данных.
- Размер блока в HDFS обычно 128 МБ. Поэтому большой файл в 1 ГБ автоматически разобьётся на 8 партиций.
#### **Best practice:**
- Для маленьких файлов используйте меньше партиций:
    `sc.textFile("small_file.txt", minPartitions=2)`
### **8. Не злоупотребляйте `groupByKey`**
- `groupByKey` требует большого объёма shuffle, так как все данные с одинаковыми ключами перемещаются в одну партицию.
- Используйте `reduceByKey` или `aggregateByKey` вместо `groupByKey`, если это возможно.
#### **Пример:**
- Вместо:
    `rdd.groupByKey().mapValues(len)`
    
- Используйте:
    `rdd.reduceByKey(lambda a, b: a + b)`

### **9. Уменьшайте данные перед записью**

- Если вы пишете RDD на диск (например, через `saveAsTextFile`), сократите количество партиций перед записью.  
    Например, вместо записи с 100 партициями:
    
    `rdd.saveAsTextFile("output")`
    
    Уменьшите до разумного числа (например, 8):

    `rdd.coalesce(8).saveAsTextFile("output")`

### **10. Учитывайте, что слишком много партиций — тоже плохо**

- Если данных мало, а партиций много, Spark создаёт много пустых или почти пустых партиций, что снижает эффективность.
- В таких случаях лучше объединить данные:
    
    `rdd.coalesce(1)`

### **11. Кеширование и управление памятью**

- Если RDD будет использоваться многократно, закешируйте его, чтобы Spark не пересоздавал данные:

    `cached_rdd = rdd.cache()`