5. Коротко: Spark запускает «дубликаты» медленных задач (stragglers) на других executors и принимает результат того, кто финишировал раньше.
    

Когда полезно: непостоянные тормоза диска/сети/узла, «редкие» медленные партиции. Когда вредно: задачи с побочными эффектами (неидемпотентные записи), Streaming.

Как включить/настроить:

`spark.conf.set("spark.speculation", "true") # Имеются параметры порога и квантиля: # spark.speculation.quantile (какую долю задач считать «нормой», напр. 0.75) # spark.speculation.multiplier (во сколько раз дольше «нормы» считать таск медленным) # spark.speculation.interval (периодичность проверки)`

На собесе можно сказать: включаю точечно для batch-jobs с idempotent-выводом; смотрю, чтобы не было двойной записи.