### **Сериализация в Spark: ключевые моменты**

**Сериализация** — это процесс **преобразования объектов** (например, данных или функций) в формат, который может быть передан между узлами кластера или сохранён в памяти/на диске..


Spark активно использует сериализацию для:

1. **Передачи данных** между драйвером и исполнителями (executors).
2. **Кэширования данных** в памяти или записи на диск.
3. **Обработки данных** в распределённой среде.

### **Почему это важно?**

- Spark передаёт задачи (tasks) и их зависимости на узлы кластера.
- Если объекты **не сериализуемы**, Spark **не может распределить** задачи на исполнители, и вычисления завершаются с ошибкой.

### **Краткий итог:**

- Проблемы сериализации возникают, когда Spark не может передать объекты или функции на узлы.
- Лечится созданием объектов **внутри функций трансформации**.
- Тебе сейчас достаточно помнить, что **данные и функции должны быть "сериализуемыми"**, и Spark всегда требует это для распределённой обработки.