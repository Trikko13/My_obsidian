1. Перекос данных (data skew)  
    Коротко (что сказать): Перекос — это неравномерное распределение строк по ключам/партициям: одна или несколько партиций/ключей содержат на порядки больше данных, чем остальные. Симптом — «одна-две» долгие таски, пока весь job простаивает.
    

Как увидеть в Spark UI:

- Stages → конкретный stage: Max Task Duration сильно больше Median; одна таска «висит» на таймлайне.
    
- Высокий Shuffle Read у 1–2 тасок/экзекьюторов; большие Spill(ons)/GC Time на этих тасках.
    
- Executors: один executor прочитал/записал намного больше shuffle-данных.
    

Что делать (паттерны):

- Логика: разбить «горячие» ключи (salting), сделать двухфазную агрегацию, применить broadcast/репликацию малого набора для join.
    
- Конфигурация: включить AQE (адаптивное выполнение), оно умеет резать «толстые» партиции и подменять джоин.
    
    `spark.conf.set("spark.sql.adaptive.enabled", "true") spark.conf.set("spark.sql.adaptive.skewJoin.enabled", "true")`
    
- Модель данных: переспартиционировать по ключу (repartition), предусмотреть bucketing/partitioning в Hive.