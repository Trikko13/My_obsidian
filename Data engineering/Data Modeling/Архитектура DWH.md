Архитектура классического DWH (хранилища данных) обычно строится **по слоям**, которые выполняют разные функции: от первичного приёма и очистки данных, до формирования витрин (Data Marts) для анализа. Ниже рассмотрим эти слои и проведём аналогию, чтобы было проще понять.

---

## 1. Основные слои DWH

1. **Первичный (staging или landing) слой**
    
    - **Задача**: собрать данные из разных источников (OLTP-системы, файлы, API и т.д.) и подготовить их к дальнейшей обработке.
    - **Характеристики**:
        - Данные могут храниться в сыро́м виде или слегка преобразованном (минимально, чтобы привести к единому формату).
        - Этот слой часто называют «промежуточным» или «сырьевым» (raw zone).
    - **Аналогия**: Представьте, что грузовики привозят товары на склад. Сначала они выгружаются в **зону приёмки** (staging area), где товары ещё не рассортированы и не разложены по полкам.
2. **Центральный (core, корпоративный) слой**
    
    - **Задача**: объединить данные из всех источников, очистить, нормализовать (или денормализовать по необходимости), привести к единому стандарту (conformed dimensions и т.п.). Это сердце DWH, где хранятся **консолидированные и исторические данные**.
    - **Характеристики**:
        - Структура может быть нормализованной (подход Инмона) или же звёздной/снежинкой (подход Кимбалла).
        - На этом этапе снимаются дубликаты, устраняются конфликты и несоответствия (например, в справочниках).
        - Часто называют **Enterprise Data Warehouse (EDW)**.
    - **Аналогия**: Когда товары прошли зону приёмки, их **перевозят в центральную часть склада**. Там всё аккуратно расставлено по полкам и зонам: все товары имеют ярлыки, категории, учтено их количество и свойства.
3. **Слой витрин (Data Marts)**
    
    - **Задача**: предоставить данные для конкретных бизнес-процессов или подразделений (финансы, маркетинг, продажи и т.д.) в удобном виде (обычно денормализованном), чтобы аналитики могли быстро строить отчёты и дашборды.
    - **Характеристики**:
        - Могут быть звёздной (star) или снежиночной (snowflake) схемами.
        - Оптимизированы под чтение и агрегацию (быстрая выборка).
        - Часто содержат предрасчитанные показатели (например, «сумма продаж за неделю»), чтобы ускорять аналитику.
    - **Аналогия**: Представьте в центральном складе есть специальные **“витрины” или “презентационные зоны”**, куда складываются товары уже отсортированные по популярности, акциям, категориям — чтобы человеку было проще взять нужные товары без долгих поисков по всему складу.

---

## 2. Краткая схема потоков данных

1. **Источники** (OLTP-системы, файлы, API)
2. **Первичный слой (Staging)**
    - Сырой импорт данных.
    - Этапы: загрузка (Extract) + первоначальная очистка (Transform).
3. **Центральный слой (Core/EDW)**
    - Консолидация, нормализация/денормализация, историзация (SCD) и т.д.
    - Считается «сердцем» DWH.
4. **Слой витрин (Data Marts)**
    - Звёздные/снежиночные схемы или иные структуры, удобные для анализа.
    - Оптимизация под бизнес-процессы.
5. **BI/Аналитические инструменты**
    - Tableau, Power BI, Qlik, Looker и т.п.
    - Подключаются к витринам и формируют отчёты.

---

## 3. Расширенная аналогия

Представьте, что у вас есть **большой склад** (DWH), и вы управляете потоками товаров:

1. **Первичная зона (Staging)** — «Приёмка»
    
    - Грузовики разных поставщиков (источников данных) привозят товары в разном состоянии: где-то товар упакован, где-то разбросан.
    - В приёмочной зоне вы **быстро проверяете**, всё ли доехало, нет ли явного брака или несоответствий в документах.
    - Вы **временно** складываете всё в этой зоне, пока не примете решение, как дальше сортировать.
2. **Центральный зал (Core/EDW)** — «Главный склад»
    
    - Когда убедились, что товар в порядке, переносите его в основное хранилище.
    - Там у вас уже **чёткая система полок и ячеек**, на каждой полке лежат определённые категории товаров.
    - Вы **обновляете учёт**, чтобы знать, сколько товара в наличии, кто поставщик, каков срок годности и т.д.
3. **Витрины (Data Marts)** — «Отдельные стеллажи/секции для быстрой отгрузки»
    
    - Если у вас есть **популярные товары**, которые часто запрашивают клиенты, вы ставите их поближе к выходу или делаете из них «витрину».
    - Здесь все товары **уже подготовлены**, рассортированы и можно моментально их получить без долгих поисков.
    - В контексте данных — это **предрасчитанные отчёты, агрегаты**, структурированные так, чтобы бизнес-пользователи могли быстро получать нужную информацию.

---

## 4. Итоговое понимание

- **Зачем нужен первичный слой?**  
    Для временного хранения и минимальной предобработки данных из разных источников перед тем, как они попадут в главное хранилище.
    
- **Зачем нужен центральный слой?**  
    Чтобы **интегрировать** все данные в едином формате, очистить и обеспечить целостность, ведение истории и качественную основу (EDW). Именно здесь формируется “единая версия правды” о всех бизнес-процессах.
    
- **Зачем нужны витрины (Data Marts)?**  
    Чтобы предоставить **быструю, удобную и предметно-ориентированную аналитику**. Не всем пользователям нужно «погружаться» в детали EDW. Витрины готовят данные под их сценарии (например, финансы хотят видеть отчёт по расходам, маркетинг — по конверсиям).
    

Таким образом, трёхслойная архитектура (Staging → Core → Data Marts) оптимальна для большинства классических DWH-проектов:

1. **Собираем (Extract)** данные в первичном слое,
2. **Обрабатываем (Transform) и сохраняем (Load)** в центральном хранилище,
3. **Фильтруем, агрегируем, оптимизируем** под нужды аналитиков и выкладываем в витрины.

## 1. Когда нужна нормализация и когда денормализация?

### Нормализация

- **Когда**:
    - Необходимо обеспечить целостность и согласованность данных.
    - Нужно минимизировать дублирование (что снижает риск расхождений и уменьшает объём хранения).
    - Важны быстрая вставка/обновление данных и точность транзакций (OLTP-системы, Inmon-подход в Core Layer).
- **Зачем**:
    - Легче поддерживать данные в актуальном состоянии (одно место для правок).
    - Устраняются аномалии вставки/удаления/обновления.

### Денормализация

- **Когда**:
    - Важнее скорость чтения и аналитических запросов, чем экономия места.
    - Требуются быстрые агрегаты/отчёты (OLAP-системы, Data Marts в Kimball-подходе).
    - Нужно упростить запросы для бизнес-пользователей (меньше JOIN’ов).
- **Зачем**:
    - Повышается производительность аналитических запросов.
    - Сокращается количество JOIN’ов при чтении.
    - Упрощается логика запросов, особенно в схемах «звезда» или «снежинка».

**Итого**:

- _OLTP_ (операционная база, транзакции) — почти всегда **нормализованные** структуры (3NF) для поддержки ACID-транзакций.
- _Core (EDW)_ в подходе Инмона — обычно **3NF** или приближенная к этому.
- _Data Marts_ в подходе Кимбалла — обычно **денормализованные** (звезда, снежинка), чтобы ускорить анализ.

---

## 2. Могут ли звёздная и снежиночная схемы быть как в Data Marts, так и в Core Layer?

### Теоретически — да

- **Core layer** (EDW) может быть:
    - **Нормализованным** (Inmon).
    - **ДимENSIONAL** (Kimball) — то есть в виде звёзд/снежинок, если вы используете «bottom-up» подход.

### Практически

- В **Inmon-подходе**:
    - Центральное хранилище (Core) часто строится в 3NF.
    - **Витрины (Data Marts)** — уже звезда или снежинка (денормализация).
- В **Kimball-подходе**:
    - Весь DWH можно считать набором взаимосвязанных **витрин** (Data Marts) в звёздных/снежиночных схемах.
    - При этом иногда говорят, что «Core» — это просто совокупность всех «звёзд», но логически он всё равно денормализован.

Итого:

- **Звезда/снежинка** чаще всего встречается **в витринах**, потому что они оптимизированы под чтение.
- Но при желании или в Kimball-подходе **весь Core** может быть димENSIONAL (звезда/снежинка).

---

## 3. Как снимаются дубликаты и несоответствия в Core Layer?

Когда данные грузятся из **Staging** в **Core**, обычно происходит:

1. **Очистка данных (Data Cleaning)**
    
    - Удаление или маркировка дублей.
    - Проверка форматов (например, телефон, email).
    - Стандартизация справочников (страны, регионы, валюты) и т.п.
2. **Сопоставление (Matching)**
    
    - С помощью бизнес-ключей (например, CustomerID) или мастер-данных (MDM) совмещают записи, которые относятся к одному объекту (один клиент, один товар).
    - Если источники дают противоречивые данные, выбирают приоритетный источник или проводят merge-логику.
3. **Deduplication**
    
    - Иногда приходят **дубли**, где ключи идентичны, но записи отличаются по полям (ошибки источника).
    - Используются правила золотой записи (Golden Record), где выбирают «самые свежие и достоверные» поля.
4. **Surrogate Key (Суррогатный ключ)**
    
    - В DWH часто вводят собственные суррогатные ключи (например, `customer_sk`) вместо оригинальных `customer_id` из системы-источника, что помогает унифицировать и избегать коллизий ключей.
5. **SCD (Slowly Changing Dimensions)**
    
    - Для измерений (клиентов, продуктов, сотрудников) ведётся история изменений, чтобы сохранить «как было тогда» и «как стало сейчас». Это тоже часть гармонизации данных.

**Инструменты**:

- ETL-платформы (Informatica, Talend, SSIS, Pentaho).
- Скрипты на Python/SQL, где прописывается логика «уникализации» и «сопоставления».
- MDM-системы (Master Data Management) в крупных организациях.

---

## 4. «OLTP-процессы служат лишь для того, чтобы загнать данные в Staging? OLTP — это один из источников? Но это же механизм, обработки данных, а не система…»

### Пояснение

- **OLTP** (On-Line Transaction Processing) — это _класс систем_, которые обрабатывают оперативные транзакции (продажи, заказы, платежи и т.д.).
- С точки зрения DWH, **OLTP-база** (или несколько таких баз) действительно является **одним из основных источников** данных:
    - Каждый день (или чаще) забираем транзакции из OLTP, складываем в **Staging**, потом в **Core**.
- Но в целом OLTP _не «служит только»_ для загрузки в DWH.
    - Его _основная бизнес-функция_ — **оперативная работа**: проводить продажи, проводить банковские транзакции и т.д.
    - То есть OLTP-система функционирует самостоятельно (интернет-магазин, CRM, ERP), а не только ради выгрузки в DWH.

### Почему говорят «OLTP — система, а не просто механизм»?

- Часто мы называем OLTP **СУБД** (PostgreSQL, Oracle, MS SQL) в транзакционном режиме + прикладное ПО (интернет-магазин, ERP).
- Это полноценная среда, где есть:
    - Таблицы (обычно в 3NF).
    - Логика транзакций (ACID).
    - Пользователи, выполняющие транзакции (покупатели, бухгалтеры).
- **Да**, с точки зрения DWH, такая OLTP-база — «источник данных». Но это лишь _одна из_ её ролей, потому что сама по себе она существует для оперативной работы бизнеса.

---

### Выводы

1. **Нормализация** нужна там, где важна целостность и минимум дублирования (OLTP, Core в Inmon). **Денормализация** для быстрой аналитики (OLAP, Data Marts, Kimball).
2. **Звездная/снежиночная** схема чаще на уровне **витрин**, но может быть и в Core (особенно в Kimball-подходе).
3. **Дубликаты и несоответствия** снимаются в **Core Layer** через ETL/ELT-процессы: очистка, выравнивание, сопоставление, SCD.
4. **OLTP**-система — это **один из главных источников** для DWH, но её основная функция — выполнение транзакций в реальном времени, а не только выгрузка данных.